
# Real-time Avatar Synthesis: Papers and Code

This repository curates a collection of influential papers which have released their codebase focusing on real-time avatar synthesis. Each entry provides insights into the methodology and performance benchmarks of the models.

## 1. GaussianTalker

**Paper Title**: "GaussianTalker: Real-Time High-Fidelity Talking Head Synthesis with Audio-Driven 3D Gaussian Splatting"

**Description**: This model leverages audio-driven 3D Gaussian splatting to synthesize talking heads with high fidelity in real time.

**Performance Claim**: Achieves over 120 FPS on a single NVIDIA RTX 3090 GPU.

**GitHub Repository**: [GaussianTalker](https://github.com/KU-CVLAB/GaussianTalker)

## 2. GeneFace++

**Paper Title**: "GeneFace++: Generalized and Stable Real-Time 3D Talking Face Generation"

**Description**: GeneFace++ offers a generalized and stable approach for generating 3D talking faces in real time. This repository hosts the official implementation.

**Performance Claim**: 45 FPS on a single NVIDIA RTX 3090 GPU.

**GitHub Repository**: [GeneFace++](https://github.com/yerfor/GeneFacePlusPlus)

## 3. V-Express

**Paper Title**: "V-Express: Real-time Talking Head Video Generation"

**Description**: V-Express is designed to generate talking head videos in real time, controlled by a reference image, an audio input, and a sequence of V-Kps images.

**Performance Claim**: Real-time inference capabilities with enhancements (LoRA) to be released soon.

**GitHub Repository**: [V-Express](https://github.com/tencent-ailab/V-Express)